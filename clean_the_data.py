import pandas as pd
import string
import csv
import nltk
import re
import numpy as np
from gensim import corpora
from collections import defaultdict
from sklearn.feature_extraction.text import CountVectorizer
from pprint import pprint  # pretty-printer

f_data = pd.read_csv('train.csv', index_col=None, header=0, engine='python')

print(f_data.describe())

record_num = int(f_data.describe().iloc[0, 0])

# æŸ¥çœ‹ç¬¬ä¸€è¡Œæ‰€æœ‰æ•°æ®
# print(f_data.iloc[0, :])
documents = []


for i in range(record_num):
    record = f_data.iloc[i, :]
    documents.append(record['review'])
    # message = record['review'].split()


# print(documents)

# remove common words and tokenize
stoplist = set('for a of the and to in is an to , \' : ? . # $ & ( ) â€˜ â€œ + ...'.split())
texts = [[word for word in document.lower().split() if word not in stoplist]
         for document in documents]

# for p in range(len(texts)):
#     for f in range(len(texts[p])):
#         if texts[p][f].isdigit():
#             texts[p][f] = '+'

# é™¤å»æ•°å­—
texts = [[token for token in text if token.isdigit() is False] for text in texts]

# å¦‚æœåªä¿ç•™å­—ç¬¦ä¸²å’Œè¡¨æƒ…
# texts = [[token for token in text if (re.match('^[a-z]+$', token) or
#                                       'ğŸ˜’' in token or
#                                       'ğŸ˜‚' in token or
#                                       'ğŸ˜Š' in token or
#                                       'ğŸ˜œ' in token or
#                                       'ğŸ¤‘' in token or
#                                       'ğŸ˜' in token or
#                                       'ğŸ˜š' in token or
#                                       'ğŸ˜' in token or
#                                       'ğŸ˜˜' in token or
#                                       'ğŸ˜²' in token or
#                                       'ğŸ’ƒ' in token or
#                                       'ğŸ‘Š' in token
#                                       )] for text in texts]

# åªä¿ç•™å­—ç¬¦ä¸²
texts = [[token for token in text if (re.match('^[a-z]+$', token))] for text in texts]
# print(texts)
# for p in range(len(texts)):
#     for f in range(len(texts[p])):
#         if texts[p][f].isdigit():
#             print('?')


# æ˜¯å¦åˆ é™¤åªå‡ºç°ä¸€æ¬¡çš„å‘¢
frequency = defaultdict(int)
for text in texts:
    for token in text:
        frequency[token] += 1

texts = [[token for token in text if frequency[token] > 1] for text in texts]

# pprint(texts)

dictionary = corpora.Dictionary(texts)
dictionary.save('pf.dict')  # store the dictionary, for future reference

# ğŸçš„7000å¤šç»´å‘é‡
print(dictionary)
# è¾“å‡ºå­—å…¸mapping
print(dictionary.token2id)

dictionary.save_as_text("pf.txt")

# tryit = corpora.Dictionary('dictionary')
# print(tryit)

# æµ‹è¯•ä¸€ä¸‹
new_doc = "Affia ki"
new_vec = dictionary.doc2bow(new_doc.lower().split())
new_vec2 = dictionary.doc2idx(new_doc.lower().split())
for j in range(len(new_vec2)):
    if new_vec2[j] == -1:
        new_vec2[j] = 0
print(new_vec)
print(new_vec2)


msg = []
critic = []

for i in range(record_num):
    record = dictionary.doc2idx(f_data.iloc[i, :]['review'].lower().split())
    msg.append(record)
    if f_data.iloc[i, :]['label'] == 'Positive':
        critic.append(1)
    else:
        critic.append(0)

numpy_array_msg = np.array(msg)

numpy_array_critic = np.array(critic)
need = np.array([numpy_array_msg, numpy_array_critic])

# print(need)

np.save('pf.npy', need)

msg2 = []

for i in range(record_num):
    record = dictionary.doc2idx(f_data.iloc[i, :]['review'].lower().split())
    if f_data.iloc[i, :]['label'] == 'Positive':
        record.append(1)
    else:
        record.append(0)
    msg2.append(np.array(record))

numpy_array_msg2 = np.array(msg2)
need2 = np.array(msg2)

# print(need2)

np.save('pf2.npy', need2)


need3 = []
for i in range(record_num):
    critic = []
    df = []
    record = dictionary.doc2idx(f_data.iloc[i, :]['review'].lower().split())
    for j in range(len(record)):
        if record[j] == -1:
            record[j] = 0
    df.append(record)
    if f_data.iloc[i, :]['label'] == 'Positive':
        critic.append(1)
        df.append(critic)
    else:
        critic.append(0)
        df.append(critic)
    need3.append(df)

# print(np.array(need3))

np.save('pf3.npy', np.array(need3))

# åˆ›å»ºè¯è¢‹æ¨¡å‹
# vectorizer = CountVectorizer()
#
# # ä½¿ç”¨ç»™å®šçš„è¯­æ–™åº“æ¥è®­ç»ƒè¯¥æ¨¡å‹
# vectorizer.fit_transform(documents)
# # è¯è¡¨ä¸­çš„æ¯ä¸€ç»´ç›¸å½“äºä¸€ä¸ªç‰¹å¾
# print(vectorizer.get_feature_names())
#
# # æŸ¥çœ‹è¯è¡¨ä¸­å•è¯å¯¹åº”çš„ç´¢å¼•
# print(vectorizer.vocabulary_)
#
# get_out = "dictionary"
#
#
# test = ['bhi tou a app']
# result = vectorizer.transform(test)
# # a å’Œ appleä¸å­˜åœ¨è¯è¡¨ä¸­ï¼Œä¼šç›´æ¥å¿½ç•¥æ‰
# print(result.toarray())
